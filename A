import pandas as pd

df = pd.read_csv("your_file.csv")
documents = df.apply(lambda row: ' | '.join([f"{col}: {row[col]}" for col in df.columns]), axis=1).tolist()


from sentence_transformers import SentenceTransformer
import numpy as np
import faiss

# Load embedding model
embed_model = SentenceTransformer('all-MiniLM-L6-v2')
document_embeddings = embed_model.encode(documents)

# Index with FAISS
dimension = document_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(document_embeddings))


def retrieve(query, k=3):
    query_vec = embed_model.encode([query])
    distances, indices = index.search(query_vec, k)
    return [documents[i] for i in indices[0]]
from transformers import pipeline

# Use a local or Hugging Face model for generation
qa_pipeline = pipeline("text-generation", model="tiiuae/falcon-7b-instruct", device_map="auto")

def answer_query(query):
    context = "\n".join(retrieve(query))
    prompt = f"Based on the following data:\n{context}\n\nAnswer the question: {query}"
    result = qa_pipeline(prompt, max_new_tokens=150, do_sample=True)
    return result[0]['generated_text']
print(answer_query("What is the customer satisfaction score for March 2023?"))
